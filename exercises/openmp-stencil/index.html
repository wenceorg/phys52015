<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Parallelisation of a simple stencil #  We&rsquo;ll be running these exercises on Hamilton or COSMA, so remind yourself of how to log in and transfer code if you need to.
Blurring an image #  One can blur or smooth the edges of an image by convolving the image with a normalised box kernel. Every output pixel \( g_{k, l} \) is created from the mean of the input image pixel \(f _{k, l}\) and its eight neighbours."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="OpenMP: stencils"><meta property="og:description" content="Parallelisation of a simple stencil #  We&rsquo;ll be running these exercises on Hamilton or COSMA, so remind yourself of how to log in and transfer code if you need to.
Blurring an image #  One can blur or smooth the edges of an image by convolving the image with a normalised box kernel. Every output pixel \( g_{k, l} \) is created from the mean of the input image pixel \(f _{k, l}\) and its eight neighbours."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/phys52015/exercises/openmp-stencil/"><meta property="article:modified_time" content="2022-04-07T18:13:40+01:00"><title>OpenMP: stencils | PHYS52015 – Introduction to HPC</title><link rel=manifest href=/phys52015/manifest.json><link rel=icon href=/phys52015/favicon.png type=image/x-icon><link rel=stylesheet href=/phys52015/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/phys52015/logo.svg alt=Logo><h2><a href=/phys52015>PHYS52015 – Introduction to HPC</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/phys52015/setup/remote/>Remote editing/development</a></li><li><a href=/phys52015/setup/hamilton-quickstart/>Hamilton access & quickstart</a></li><li><a href=/phys52015/setup/byod/>Local setup</a></li><li><a href=/phys52015/setup/configuration/>ssh configuration</a></li><li><a href=/phys52015/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/phys52015/exercises/hello/>Parallel Hello World</a></li><li><a href=/phys52015/exercises/openmp-loop/>OpenMP: parallel loops</a></li><li><a href=/phys52015/exercises/openmp-stencil/ class=active>OpenMP: stencils</a></li><li><a href=/phys52015/exercises/openmp-reduction/>OpenMP: synchronisation</a></li><li><a href=/phys52015/exercises/mpi-ring/>MPI: messages round a ring</a></li><li><a href=/phys52015/exercises/mpi-pi/>MPI: Calculating π</a></li><li><a href=/phys52015/exercises/mpi-ping-pong/>MPI: ping-pong latency</a></li><li><a href=/phys52015/exercises/mpi-collectives/>MPI: simple collectives</a></li><li><a href=/phys52015/exercises/mpi-stencil/>MPI: domain decomposition and halo exchanges</a></li></ul></li><li><a href=/phys52015/coursework/>Coursework: stencils and collectives</a></li><li><span>Notes</span><ul><li><a href=/phys52015/notes/introduction/>Introduction and motivation</a></li><li><span>Theory & concepts</span><ul><li><a href=/phys52015/notes/theory/scaling-laws/>Parallel scaling laws</a></li><li><a href=/phys52015/notes/theory/hardware-parallelism/>Parallelism in hardware: an overview</a></li><li><a href=/phys52015/notes/theory/concepts/>Parallel patterns</a></li></ul></li><li><a href=/phys52015/notes/openmp/>OpenMP</a><ul><li><a href=/phys52015/notes/openmp/intro/>What is OpenMP?</a></li><li><a href=/phys52015/notes/openmp/loop-parallelism/>Loop parallelism</a></li><li><a href=/phys52015/notes/openmp/collectives/>Collectives</a></li></ul></li><li><a href=/phys52015/notes/mpi/>MPI</a><ul><li><a href=/phys52015/notes/mpi/point-to-point/>Point-to-point messaging in MPI</a></li><li><a href=/phys52015/notes/mpi/point-to-point-nb/>Non-blocking point-to-point messaging</a></li><li><a href=/phys52015/notes/mpi/collectives/>Collectives</a></li><li><a href=/phys52015/notes/mpi/advanced/>Advanced topics</a></li></ul></li></ul></li><li><a href=/phys52015/resources/>Further resources</a></li><li><a href=/phys52015/acknowledgements/>Acknowledgements</a></li><li><span>Past editions</span><ul><li><span>2020/21</span><ul><li><a href=/phys52015/past-editions/2020-21/coursework/>Coursework: parallel dense linear algebra</a></li></ul></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/phys52015/svg/menu.svg class=book-icon alt=Menu></label>
<strong>OpenMP: stencils</strong>
<label for=toc-control><img src=/phys52015/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#blurring-an-image>Blurring an image</a></li><li><a href=#parallelisation>Parallelisation</a></li><li><a href=#parallel-scaling>Parallel scaling</a></li></ul></nav></aside></header><article class=markdown><blockquote class="book-hint warning"><span>This course page was updated until March 2022 when I left Durham University.
For future updates, please visit
the <a href=https://durham-phys52015.github.io/>new version
of the course pages</a>.</span></blockquote><h1 id=parallelisation-of-a-simple-stencil>Parallelisation of a simple stencil
<a class=anchor href=#parallelisation-of-a-simple-stencil>#</a></h1><p>We&rsquo;ll be running these exercises on Hamilton or COSMA, so remind
yourself of how to log in and transfer code <a href=https://teaching.wence.uk/phys52015/setup/hamilton-quickstart/>if you need to</a>.</p><h2 id=blurring-an-image>Blurring an image
<a class=anchor href=#blurring-an-image>#</a></h2><p>One can blur or smooth the edges of an image by convolving the image
with a <a href=https://en.wikipedia.org/wiki/Box_blur>normalised box</a>
kernel. Every output pixel \( g_{k, l} \) is created from the mean
of the input image pixel \(f _{k, l}\) and its eight neighbours.</p><p>$$
g_{k,l} = \frac{1}{9} \begin{bmatrix} 1 & 1 & 1\\ 1 & 1 & 1\\ 1&1&1
\end{bmatrix} * f_{k, l}
$$</p><p>This can be implemented by a loop over every pixel of the image,
accessing some a small <em>stencil</em> of data.</p><p>This computational pattern appears in both image processing and finite
difference discretisations of partial differential equations (there is
more on the computational aspects of this in
<a href=https://teaching.wence.uk/comp52315>COMP52315</a>, and the numerics in
<a href="https://www.dur.ac.uk/postgraduate.modules/module_description/?year=2021&module_code=COMP52215">COMP52215</a>
if you&rsquo;re interested).</p><p>The code and images are in the <a href=https://github.com/wenceorg/phys52015>repository</a> in the
<code>code/blur_image/</code> subdirectory.</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh>$ <span style=color:#111>cd</span> code/blur_image
$ ls
images openmp vec
</code></pre></div><p>The <code>images</code> directory contains images in
<a href=https://en.wikipedia.org/wiki/Netpbm>PPM</a> format for that will serve
as input to our program. We&rsquo;re going to be working in the <code>openmp</code> subdirectory.</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh>$ <span style=color:#111>cd</span> openmp
$ ls
Makefile  filters.c io.c      main.c    proto.h
</code></pre></div><p>There is some source code and a
<a href=https://www.gnu.org/software/make/><code>Makefile</code></a> that provides a
recipe for how to build the executable. It is just a text file and can
be edited with your favourite text editor. By running <code>make</code> you build
the executable.</p><p>Before we do this, we&rsquo;ll have to load the right compiler modules.
We&rsquo;ll use the intel compiler for this exercise, since it produces
better reports than gcc.</p><div class=book-tabs><input type=radio class=toggle name=tabs-compiler-modules id=tabs-compiler-modules-0 checked>
<label for=tabs-compiler-modules-0>Hamilton</label><div class="book-tabs-content markdown-inner"><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh>intel/xe_2018.2
gcc/9.3.0
</code></pre></div></div><input type=radio class=toggle name=tabs-compiler-modules id=tabs-compiler-modules-1>
<label for=tabs-compiler-modules-1>COSMA</label><div class="book-tabs-content markdown-inner"><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh>intel_comp/2018
</code></pre></div></div></div><p>To confirm that everything works, run the code on one of the input
images to blur it.</p><h2 id=parallelisation>Parallelisation
<a class=anchor href=#parallelisation>#</a></h2><p>The code is not yet parallelised. You should parallelise the
<code>blur_mean</code> function in <code>filters.c</code>, using OpenMP.</p><p>What kind of parallelisation is appropriate here? What schedule should
you use?</p><details><summary>Solution</summary><div class=markdown-inner>The main work is done in a for loop over the output pixels. Since the
output pixels are all independent, we can use a simple <code>#pragma omp parallel for</code> with a static schedule.
<a href=https://teaching.wence.uk/phys52015/code/blur_image/openmp/filters-solution.c><code>code/blur_image/openmp/filters-solution.c</code></a> implements this scheme.</div></details><blockquote class="book-hint info">The code reports when it is running with OpenMP enabled. If you do not
see this, even after parallelisation, check that you enabled the
relevant compiler flags in the <code>Makefile</code>.</blockquote><h2 id=parallel-scaling>Parallel scaling
<a class=anchor href=#parallel-scaling>#</a></h2><p>Having successfully parallelised the loop we&rsquo;ll look at the <a href=https://teaching.wence.uk/phys52015/notes/theory/scaling-laws/>parallel
scaling</a> of the problem.</p><blockquote class=question><h3>Question</h3><span><p>What type of scaling is the appropriate one to consider here?</p><details><summary>Solution</summary><div class=markdown-inner>Since the total amount of work is fixed, <a href=https://teaching.wence.uk/phys52015/notes/theory/scaling-laws/#amdahl><em>strong scaling</em></a> is appropriate. We are interested in how
fast we can produce the final image as we add more processes (to the
same size problem).</div></details></span></blockquote><blockquote class=exercise><h3>Exercise</h3><p>Investigate the parallel scaling by running the code in parallel using
different numbers of threads</p><details><summary>Hint</summary><div class=markdown-inner>Remember that you control the number of threads by setting the
<code>OMP_NUM_THREADS</code> environment variable. Don&rsquo;t forget to do this <em>in
your submission script</em>.</div></details><div class=book-tabs><input type=radio class=toggle name=tabs-threads id=tabs-threads-0 checked>
<label for=tabs-threads-0>Hamilton</label><div class="book-tabs-content markdown-inner">Use 1, 2, 4, 6, 8, 16, 24, 32, and 48 threads.</div><input type=radio class=toggle name=tabs-threads id=tabs-threads-1>
<label for=tabs-threads-1>COSMA</label><div class="book-tabs-content markdown-inner">Use 1, 2, 4, 6, 8, 16, and 32 threads.</div></div><p>Produce a plot of your results comparing the observed speedup to an
ideal (linear speedup). What do you observe?</p><p>To make a problem that runs for a reasonable amount of time you
probably need to use the large sample image (<code>landscape.ppm</code>). You may
also need to increase the size of the blur filter from the default
<code>n=1</code> (edit <code>main.c</code> to do this).</p><details><summary>Solution</summary><div class=markdown-inner><p>I used a static schedule. I get slightly different speedup behaviour
with <code>n=1</code> to <code>n=10</code>, which the graph below shows.</p><p>To grab the timing data in a loop, I just did the following</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh><span style=color:#00a8c8>for</span> n in <span style=color:#ae81ff>1</span> <span style=color:#ae81ff>2</span> <span style=color:#ae81ff>4</span> <span style=color:#ae81ff>6</span> <span style=color:#ae81ff>8</span> <span style=color:#ae81ff>16</span> <span style=color:#ae81ff>24</span> <span style=color:#ae81ff>32</span> 48<span style=color:#111>;</span> <span style=color:#00a8c8>do</span>
    <span style=color:#111>OMP_NUM_THREADS</span><span style=color:#f92672>=</span><span style=color:#111>$n</span> ./blur ../images/landscape.ppm output.ppm<span style=color:#111>;</span>
<span style=color:#00a8c8>done</span> <span style=color:#111>|</span> grep Blurring <span style=color:#111>|</span> cut -f <span style=color:#ae81ff>2</span> -d :
</code></pre></div><p>Then I manually copied and plotted with matplotlib.</p><figure style=width:50%><img class=scaled src=https://teaching.wence.uk/phys52015/images/auto/openmp-blur-image-scaling.svg alt="Strong scaling (speedup) for the OpenMP parallel image blurring code."><figcaption><p>Strong scaling (speedup) for the OpenMP parallel image blurring code.</p></figcaption></figure><p>Note that with $n=10$, the overall time is much longer than with
$n=1$.</p><p>A Hamilton compute node has only 24 cores, so adding more than 24
threads does not help (indeed it harms). For small $n$, more than 8
threads does not really help. I think this is because the memory
bandwidth is maxed out.</p></div></details></blockquote><blockquote class=exercise><h3>Exercise</h3><p>Having produce a scaling plot for the <a href=https://teaching.wence.uk/phys52015/notes/openmp/loop-parallelism/#loop-schedules>loop schedule</a> you selected, try repeating
the experiments with different loop schedules. For example, if you
used a <code>static</code> schedule, try with a <code>dynamic</code> or <code>guided</code> schedule.</p><p>What do you observe?</p><p>Can you explain your results thinking about whether the computational
cost is variable depending on which pixel in the image you are
blurring?</p><details><summary>Solution</summary><div class=markdown-inner><p>I run the main loop with <code>schedule(runtime)</code> to control the schedule
and do</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh><span style=color:#00a8c8>for</span> schedule in static static,100 dynamic dynamic,100 guided guided,100<span style=color:#111>;</span> <span style=color:#00a8c8>do</span>
    <span style=color:#111>echo</span> <span style=color:#111>$schedule</span>
    <span style=color:#00a8c8>for</span> n in <span style=color:#ae81ff>1</span> <span style=color:#ae81ff>2</span> <span style=color:#ae81ff>4</span> <span style=color:#ae81ff>6</span> <span style=color:#ae81ff>8</span> <span style=color:#ae81ff>16</span> 24<span style=color:#111>;</span> <span style=color:#00a8c8>do</span>
        <span style=color:#111>OMP_SCHEDULE</span><span style=color:#f92672>=</span><span style=color:#111>$schedule</span> <span style=color:#111>OMP_NUM_THREADS</span><span style=color:#f92672>=</span><span style=color:#111>$n</span> ./blur ../images/landscape.ppm output.ppm<span style=color:#111>;</span>
    <span style=color:#00a8c8>done</span> <span style=color:#111>|</span> grep Blurring <span style=color:#111>|</span> cut -f <span style=color:#ae81ff>2</span> -d :
<span style=color:#00a8c8>done</span>
</code></pre></div><p>This time I only ran with up to 24 threads, since we already
determined that more than that number is not very helpful. I also only
used $n=1$ for this case</p><p>I see the following scaling</p><figure style=width:50%><img class=scaled src=https://teaching.wence.uk/phys52015/images/auto/openmp-blur-image-schedules.svg alt="Strong scaling (speedup) for different schedules."><figcaption><p>Strong scaling (speedup) for different schedules.</p></figcaption></figure><p>This time it looks like the guided schedule is best, but this might be
misleading, since each line is normalised to itself.</p><p>We can replot these data, producing the speedup curve relative to the
best single-thread performance over all schedules. Let&rsquo;s see what that
looks like</p><figure style=width:50%><img class=scaled src=https://teaching.wence.uk/phys52015/images/auto/openmp-blur-image-schedules-best.svg alt="Strong scaling relative to best single-thread schedule (speedup) for different schedules."><figcaption><p>Strong scaling relative to best single-thread schedule (speedup) for different schedules.</p></figcaption></figure><p>In this case, it looks like the static schedule is now a bit worse. I
am not sure exactly what is going on, and one would need to do more
detailed investigation and profiling to find out.</p></div></details></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/commit/d488ecdf20e1aba21512c0e81135546a0c9a77d7 title="Last modified by Lawrence Mitchell | April 7, 2022" target=_blank rel=noopener><img src=/phys52015/svg/calendar.svg class=book-icon alt=Calendar>
<span>April 7, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/edit/main/site/content/exercises/openmp-stencil.md target=_blank rel=noopener><img src=/phys52015/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence.mitchell@durham.ac.uk>Lawrence Mitchell</a>, <a href=https://www.ippp.dur.ac.uk/~hschulz/>Holger Schulz</a>, <a href="https://www.dur.ac.uk/physics/staff/profiles/?mode=staff&id=16712">Christian Arnold</a> & <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/phys52015/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#blurring-an-image>Blurring an image</a></li><li><a href=#parallelisation>Parallelisation</a></li><li><a href=#parallel-scaling>Parallel scaling</a></li></ul></nav></aside></main></body></html>